# UCI Student Dropout Prediction

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/downloads/release/python-3100/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

This project implements a machine learning pipeline to predict student dropout and academic success based on the UCI "Predict Students' Dropout and Academic Success" dataset. It covers data cleaning, visualization of raw and cleaned data, exploratory data analysis (EDA), model building with classifiers like Logistic Regression, Random Forest, and Gradient Boosting, hyperparameter tuning, feature importance, and prediction for new students. The best model (typically Random Forest) is saved for deployment, and insights highlight academic grades and financial stability as top predictors.

**Key outcomes:**
- Class imbalance handled with stratified splitting.
- Models evaluated on metrics like Accuracy, F1-Score, and ROC-AUC.
- Feature importance reveals curricular units and tuition fees as critical factors.

## Dataset
The dataset is from the UCI Machine Learning Repository: [Predict Students' Dropout and Academic Success](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success). It includes 4424 entries with 37 features covering demographics, academic performance, and socio-economic factors. Target classes: Dropout (0), Enrolled (1), Graduate (2).

- Raw data: `data.csv` (provided in repo)
- Cleaned data: `cleaned_data.csv` (generated by running the cleaning script)

## Project Structure
- **01_Data_Loading_Cleaning.py**: Loads raw data, cleans column names, maps categorical codes to labels, encodes variables, and saves cleaned data.
- **01.1_Data_Visualization_Uncleaned.py**: Visualizes raw data distributions, class balance, outliers, and correlations.
- **02_Data_Visualization_EDA.py**: Performs EDA on cleaned data, including feature distributions, correlations, pairplots, boxplots, and mutual information scores.
- **03_Modelling.py**: Preprocesses data, trains/evaluates models (Logistic Regression, Random Forest, Gradient Boosting), tunes hyperparameters, selects the best model, and saves it along with evaluation results.
- **03_Model_NBVersion.ipynb**: Jupyter Notebook version of the modeling script for interactive exploration.
- **04_Conc_Analysis.ipynb**: Summarizes conclusions, insights from all steps, recommendations, and future work.
- **05_Prediction.py**: Loads the saved model for single student or batch predictions, outputting classes and probabilities.
- **dependencies.yml**: Conda environment file for dependencies.
- **data.csv**: Raw UCI dataset.
- **cleaned_data.csv**: Cleaned dataset (generated).
- **models/**: Directory for saved models (e.g., `RandomForest_pipeline_model.joblib`) and evaluation results (`evaluation_results.csv`).
- **feature_importance.png**: Generated plot of top feature importances.

## Installation
1. Clone the repository:
```bash
git clone https://github.com/yourusername/UCI-Student-Dropout-Prediction.git
cd UCI-Student-Dropout-Prediction
```
2. Create and activate the Conda environment:
```
conda env create -f dependencies.yml
conda activate bda_project_env
```
3. Install any additional pip dependencies if needed:
```
pip install -r requirements.txt  # If you create a requirements.txt from the yml
```

## Usage
Run the scripts in sequence:
```python 01_Data_Loading_Cleaning.py```
```python 01.1_Data_Visualization_Uncleaned.py```
```python 02_Data_Visualization_EDA.py```
```python 03_Modelling.py```
```python 05_Prediction.py```

## Results
- Model Performance: Tree-based models (Random Forest, Gradient Boosting) outperform Logistic Regression, with F1-Scores around 0.75-0.85 (exact values in models/evaluation_results.csv).
- Feature Importance: Academic features like curricular units (approved/grades) dominate, followed by admission grade, age, and financial indicators (tuition fees).
- Target Distribution: Imbalanced (Graduates ~50%, Dropouts ~32%, Enrolled ~18%).
- Insights from EDA: Strong correlations between semester grades; higher dropouts among debtors and non-scholarship holders.

## Conclusions
- Academic performance (grades, approved units) and financial stability (tuition fees, scholarships) are the strongest predictors of dropout.
- The project demonstrates a robust pipeline for educational analytics, enabling early interventions to improve retention.
- Challenges: Class imbalance affects minority class recall; addressed partially via stratification.

## Acknowledgments
### Dataset: UCI Machine Learning Repository.
[Link Text](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)
### Inspired by similar educational ML projects on GitHub.
